{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forminju/DACON_anomaly_detection_/blob/main/0227_1_2___smartfactory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKaLVHk_Usyp",
        "outputId": "9c572d16-78fb-4f40-a295-f1c0b7eb1e21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from umap import UMAP\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "# setting some globl config\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "orange_black = [\n",
        "    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n",
        "]\n",
        "plt.rcParams['figure.figsize'] = (16,9)\n",
        "plt.rcParams[\"figure.facecolor\"] = '#FFFACD'\n",
        "plt.rcParams[\"axes.facecolor\"] = '#FFFFE0'\n",
        "plt.rcParams[\"axes.grid\"] = True\n",
        "plt.rcParams[\"grid.color\"] = orange_black[3]\n",
        "plt.rcParams[\"grid.alpha\"] = 0.5\n",
        "plt.rcParams[\"grid.linestyle\"] = '--'\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "INFERENCE = True"
      ],
      "metadata": {
        "id": "YeIoTCMAeG_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1kDNwfHSFkCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        \n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "pQ1prUmDEcxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/스마트공장"
      ],
      "metadata": {
        "id": "j3OE2mOiUus_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "s5A3THjzVHEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/스마트공장/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/스마트공장/test.csv')"
      ],
      "metadata": {
        "id": "-tWVg24zVIoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_df.drop(columns=['TIMESTAMP', 'Y_Class','Y_Quality'])\n",
        "train_y = train_df['Y_Class']\n",
        "\n",
        "test_x = test_df.drop(columns=['TIMESTAMP'])"
      ],
      "metadata": {
        "id": "N86cft8kVC3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파생변수 생성"
      ],
      "metadata": {
        "id": "KNjZIHjGilhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "tzitA_0Qinff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "id": "n3k0XMkIiyNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x['LINE_PRODUCT'] = train_x['LINE'].str.cat(train_x['PRODUCT_CODE'])\n",
        "test_x['LINE_PRODUCT'] = test_x['LINE'].str.cat(test_x['PRODUCT_CODE'])"
      ],
      "metadata": {
        "id": "k2zGNX0LiqKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qualitative to quantitative\n",
        "qual_col = ['LINE', 'PRODUCT_CODE', 'LINE_PRODUCT']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    \n",
        "    for label in np.unique(test_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i]) \n",
        "print('Done.')\n",
        "     "
      ],
      "metadata": {
        "id": "Qokg-212i6PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.drop(['LINE', 'PRODUCT_CODE'],axis=1, inplace=True)\n",
        "test_x.drop(['LINE', 'PRODUCT_CODE'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Glc36faDi8_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputation 기법 적용"
      ],
      "metadata": {
        "id": "fUnMA4bH7FIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.dropna(how='all')\n",
        "test_x = test_x[train_x.columns]"
      ],
      "metadata": {
        "id": "VzmzZxuejAIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = test_x[train_x.columns]"
      ],
      "metadata": {
        "id": "Pmp528_N6T9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.dropna(how='all',axis=1)\n",
        "test_x = test_x[train_x.columns]"
      ],
      "metadata": {
        "id": "VxyFd7606WGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=50)\n",
        "\n",
        "imputer_output = imputer.fit_transform(train_x.iloc[:,1:])"
      ],
      "metadata": {
        "id": "3rM7l-Ykeaxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.iloc[:,1:] = pd.DataFrame(imputer_output, columns=train_x.iloc[:,1:].columns, index=list(train_x.iloc[:,1:].index.values));train_x"
      ],
      "metadata": {
        "id": "UgtrM00R97eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = test_x[train_x.columns]"
      ],
      "metadata": {
        "id": "x--pOUPcc5gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_output_test = imputer.transform(test_x.iloc[:,1:])"
      ],
      "metadata": {
        "id": "sYzMOWZK-PmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.iloc[:,1:] = pd.DataFrame(imputer_output_test, columns=test_x.iloc[:,1:].columns, index=list(test_x.iloc[:,1:].index.values));test_x"
      ],
      "metadata": {
        "id": "qpBjxK7B-Skx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "id": "FZstEws0ox5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vif 기반 변수 줄이기"
      ],
      "metadata": {
        "id": "8K1e7zv0Z5ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calc_vif(v):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = v.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(v.values,i) for i in range(v.shape[1])]\n",
        "\n",
        "    high_vif = vif[vif[\"VIF\"] > 5].sort_values(\"VIF\",ascending=False)\n",
        "\n",
        "    \n",
        "    return(high_vif)"
      ],
      "metadata": {
        "id": "07IZglDFZaNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = train_x.corr()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Find features with correlation greater than 0.95\n",
        "to_drop1 = [column for column in upper.columns if any(upper[column] < -0.9)]\n",
        "to_drop2 = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
        "print(to_drop1)\n",
        "print(to_drop2)\n",
        "drop=to_drop1+to_drop2"
      ],
      "metadata": {
        "id": "_Tr6yV-uZcpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(drop)"
      ],
      "metadata": {
        "id": "YnlGuHZZZmzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.drop(drop,1)\n",
        "test_x = test_x.drop(drop,1)"
      ],
      "metadata": {
        "id": "0SdkVeQxZr53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape"
      ],
      "metadata": {
        "id": "zkI569FQZ2Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = train_x.copy()\n",
        "features_test = test_x.copy()"
      ],
      "metadata": {
        "id": "trzxS7gxij-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.iloc[:,1:].columns"
      ],
      "metadata": {
        "id": "yfAZ1bV-i5Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape"
      ],
      "metadata": {
        "id": "_8VuSB2Fn7QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.shape"
      ],
      "metadata": {
        "id": "aqfQ5RCrn9ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RobustScaler"
      ],
      "metadata": {
        "id": "SIDhZx2R2d6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "id": "2h045EFbhWok"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = RobustScaler()"
      ],
      "metadata": {
        "id": "2PQ5h_pG3cJQ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train data 변환\n",
        "X_group_train = scaler.fit_transform(features_train.iloc[:,1:])\n",
        "\n",
        "#test data 변환\n",
        "X_group_test = scaler.transform(features_test.iloc[:,1:])"
      ],
      "metadata": {
        "id": "B7KVcPA6AGn8"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.iloc[:,1:] = pd.DataFrame(X_group_train, columns=train_x.iloc[:,1:].columns, index=list(train_x.iloc[:,1:].index.values));train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "wlshHUMn5AH6",
        "outputId": "eb0ac835-e9d9-4e00-8a5e-6e805337b6d4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PRODUCT_ID        X_1       X_2  X_3  X_4       X_5  X_6    X_7   X_8  \\\n",
              "0    TRAIN_000  -0.137931 -0.398010  0.0  0.0  0.000000  0.0  0.652  0.02   \n",
              "1    TRAIN_001  -0.137931 -0.398010  0.0  0.0  0.000000  0.0  0.652  0.02   \n",
              "2    TRAIN_002   1.000000  0.467662  0.0  0.0  0.190476  0.0  0.000  0.00   \n",
              "3    TRAIN_003   1.000000  0.467662  0.0  0.0  0.190476  0.0  0.000  0.00   \n",
              "4    TRAIN_004   1.000000  0.467662  0.0  0.0  0.190476  0.0  0.000  0.00   \n",
              "..         ...        ...       ...  ...  ...       ...  ...    ...   ...   \n",
              "593  TRAIN_593   0.000000 -0.248756  0.0  0.0 -0.523810  0.0  1.000  0.00   \n",
              "594  TRAIN_594  -0.137931 -0.398010  0.0  0.0  0.000000  0.0  0.652  0.02   \n",
              "595  TRAIN_595  -0.137931 -0.398010  0.0  0.0  0.000000  0.0  0.652  0.02   \n",
              "596  TRAIN_596  65.517241 -0.497512  0.0  0.0  0.666667  0.0  0.000  0.00   \n",
              "597  TRAIN_597  32.758621 -2.238806  0.0  0.0 -0.523810  0.0  3.200  0.00   \n",
              "\n",
              "     X_9  ...  X_2798  X_2799     X_2800  X_2801     X_2837  X_2839  X_2840  \\\n",
              "0    0.5  ...   -54.0   -1.46 -91.874918   -2.32  15.238095  0.0606  0.0484   \n",
              "1    0.5  ...    -4.0   -0.46  28.612477    1.68  -3.809524  0.0406  0.0984   \n",
              "2    0.0  ...    -4.0   -0.46 -33.049338   -0.32  15.238095  0.0606 -0.4316   \n",
              "3    0.0  ...    -4.0   -0.46  27.877158    0.68 -13.150183  0.0506  0.0784   \n",
              "4    0.0  ...    -4.0   -0.46 -30.948424   -0.32  15.238095  0.0706 -0.4316   \n",
              "..   ...  ...     ...     ...        ...     ...        ...     ...     ...   \n",
              "593  1.0  ...     0.0    0.00   0.000000    0.00   0.000000  0.0000  0.0000   \n",
              "594  0.5  ...    -4.0    0.54  -4.611971   -0.32   5.531136  0.0306  0.0484   \n",
              "595  0.5  ...    -4.0    0.54  -8.663733   -0.32  14.322344  0.0406  0.0484   \n",
              "596  0.0  ...     0.0    0.00   0.000000    0.00   0.000000  0.0000  0.0000   \n",
              "597  1.0  ...     0.0    0.00   0.000000    0.00   0.000000  0.0000  0.0000   \n",
              "\n",
              "       X_2842  X_2871  LINE_PRODUCT  \n",
              "0   -0.000406     0.0          -0.6  \n",
              "1    0.000413     0.0          -0.4  \n",
              "2   -0.000405     0.0          -0.6  \n",
              "3    0.000473     0.0          -0.4  \n",
              "4   -0.000403     0.0          -0.6  \n",
              "..        ...     ...           ...  \n",
              "593  0.000000     0.0           0.4  \n",
              "594 -0.000613     0.0          -0.6  \n",
              "595 -0.000542     0.0          -0.6  \n",
              "596  0.000000     0.0          -0.2  \n",
              "597  0.000000     0.0           0.2  \n",
              "\n",
              "[598 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fe3b0d6-1d01-4f5b-a6e7-8849a901e593\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>X_8</th>\n",
              "      <th>X_9</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2798</th>\n",
              "      <th>X_2799</th>\n",
              "      <th>X_2800</th>\n",
              "      <th>X_2801</th>\n",
              "      <th>X_2837</th>\n",
              "      <th>X_2839</th>\n",
              "      <th>X_2840</th>\n",
              "      <th>X_2842</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>LINE_PRODUCT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>-0.398010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-54.0</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>-91.874918</td>\n",
              "      <td>-2.32</td>\n",
              "      <td>15.238095</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>-0.000406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_001</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>-0.398010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>28.612477</td>\n",
              "      <td>1.68</td>\n",
              "      <td>-3.809524</td>\n",
              "      <td>0.0406</td>\n",
              "      <td>0.0984</td>\n",
              "      <td>0.000413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.467662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-33.049338</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>15.238095</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>-0.000405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_003</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.467662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>27.877158</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-13.150183</td>\n",
              "      <td>0.0506</td>\n",
              "      <td>0.0784</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_004</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.467662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-30.948424</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>15.238095</td>\n",
              "      <td>0.0706</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>-0.000403</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>TRAIN_593</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.248756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.523810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>TRAIN_594</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>-0.398010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>-4.611971</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>5.531136</td>\n",
              "      <td>0.0306</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>-0.000613</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>TRAIN_595</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>-0.398010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>-8.663733</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>14.322344</td>\n",
              "      <td>0.0406</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>-0.000542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>TRAIN_596</td>\n",
              "      <td>65.517241</td>\n",
              "      <td>-0.497512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>TRAIN_597</td>\n",
              "      <td>32.758621</td>\n",
              "      <td>-2.238806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.523810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.200</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>598 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fe3b0d6-1d01-4f5b-a6e7-8849a901e593')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fe3b0d6-1d01-4f5b-a6e7-8849a901e593 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fe3b0d6-1d01-4f5b-a6e7-8849a901e593');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.iloc[:,1:] = pd.DataFrame(X_group_test, columns=test_x.iloc[:,1:].columns, index=list(test_x.iloc[:,1:].index.values))"
      ],
      "metadata": {
        "id": "YvV3Yj4L4J-s"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분류기"
      ],
      "metadata": {
        "id": "5s25vdvcdRv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "7J-Ma4cpdcVj"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [['Naive Bayes :', GaussianNB()],\n",
        "               ['KNeighbours :', KNeighborsClassifier()],\n",
        "               ['SVM :', SVC()],\n",
        "               ['LogisticRegression :', LogisticRegression()],\n",
        "               ['DecisionTree :',DecisionTreeClassifier()],\n",
        "               ['RandomForest :',RandomForestClassifier()],\n",
        "               ['LGBMClassifier:', LGBMClassifier()],\n",
        "               ['XGBClassifier: ', XGBClassifier()]]"
      ],
      "metadata": {
        "id": "v3jVwB8RdTcw"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "osmote=SMOTE()\n",
        "Xs_train,ys_train=osmote.fit_resample(train_x.iloc[:,1:],train_y)\n",
        "\n",
        "print(Counter(ys_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0m5vTVMdm6b",
        "outputId": "d0785534-83dd-4efb-bfbc-a7e9c1674ca5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 407, 2: 407, 0: 407})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jqv_T-NwhD1o"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xs_train, Xs_valid, ys_train, ys_valid = train_test_split(Xs_train, ys_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NHq8LJuyhI6x"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,classifier in classifiers:\n",
        "    clf=classifier.fit(Xs_train,ys_train)\n",
        "    y_pred=classifier.predict(Xs_valid)\n",
        "    print(f'\\n {name} \\n')\n",
        "    print(f'Training Score for {name}  {clf.score(Xs_train,ys_train) * 100:.2f}' )\n",
        "    print(f'Testing Score for {name} {clf.score(Xs_valid,ys_valid) * 100:.2f}' )\n",
        "    print(f'Classification report  \\n {classification_report(ys_valid,y_pred)}' )\n",
        "    print(f'Confusion matrix  \\n {confusion_matrix(ys_valid,y_pred)}' )\n",
        "    #print(f'ROC AUC  : {roc_auc_score(valid_y,y_pred)}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D63ZUf_MkPy0",
        "outputId": "fcb0bb68-1add-47b3-c3bc-606a55591f3e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Naive Bayes : \n",
            "\n",
            "Training Score for Naive Bayes :  44.47\n",
            "Testing Score for Naive Bayes : 45.31\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.40      0.49        83\n",
            "           1       0.41      0.85      0.55        82\n",
            "           2       0.35      0.10      0.16        80\n",
            "\n",
            "    accuracy                           0.45       245\n",
            "   macro avg       0.47      0.45      0.40       245\n",
            "weighted avg       0.47      0.45      0.40       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[33 41  9]\n",
            " [ 6 70  6]\n",
            " [12 60  8]]\n",
            "\n",
            " KNeighbours : \n",
            "\n",
            "Training Score for KNeighbours :  74.49\n",
            "Testing Score for KNeighbours : 66.94\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.92      0.75        83\n",
            "           1       0.76      0.27      0.40        82\n",
            "           2       0.69      0.82      0.75        80\n",
            "\n",
            "    accuracy                           0.67       245\n",
            "   macro avg       0.69      0.67      0.63       245\n",
            "weighted avg       0.69      0.67      0.63       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[76  4  3]\n",
            " [33 22 27]\n",
            " [11  3 66]]\n",
            "\n",
            " SVM : \n",
            "\n",
            "Training Score for SVM :  49.69\n",
            "Testing Score for SVM : 48.16\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.47      0.53        83\n",
            "           1       0.41      0.74      0.53        82\n",
            "           2       0.53      0.23      0.32        80\n",
            "\n",
            "    accuracy                           0.48       245\n",
            "   macro avg       0.52      0.48      0.46       245\n",
            "weighted avg       0.52      0.48      0.46       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[39 37  7]\n",
            " [12 61  9]\n",
            " [12 50 18]]\n",
            "\n",
            " LogisticRegression : \n",
            "\n",
            "Training Score for LogisticRegression :  51.74\n",
            "Testing Score for LogisticRegression : 48.16\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.52      0.52        83\n",
            "           1       0.49      0.48      0.48        82\n",
            "           2       0.43      0.45      0.44        80\n",
            "\n",
            "    accuracy                           0.48       245\n",
            "   macro avg       0.48      0.48      0.48       245\n",
            "weighted avg       0.48      0.48      0.48       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[43 15 25]\n",
            " [20 39 23]\n",
            " [19 25 36]]\n",
            "\n",
            " DecisionTree : \n",
            "\n",
            "Training Score for DecisionTree :  100.00\n",
            "Testing Score for DecisionTree : 83.27\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86        83\n",
            "           1       0.80      0.72      0.76        82\n",
            "           2       0.85      0.90      0.87        80\n",
            "\n",
            "    accuracy                           0.83       245\n",
            "   macro avg       0.83      0.83      0.83       245\n",
            "weighted avg       0.83      0.83      0.83       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[73  9  1]\n",
            " [11 59 12]\n",
            " [ 2  6 72]]\n",
            "\n",
            " RandomForest : \n",
            "\n",
            "Training Score for RandomForest :  100.00\n",
            "Testing Score for RandomForest : 91.43\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        83\n",
            "           1       0.87      0.88      0.87        82\n",
            "           2       0.99      0.91      0.95        80\n",
            "\n",
            "    accuracy                           0.91       245\n",
            "   macro avg       0.92      0.91      0.91       245\n",
            "weighted avg       0.92      0.91      0.91       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[79  4  0]\n",
            " [ 9 72  1]\n",
            " [ 0  7 73]]\n",
            "\n",
            " LGBMClassifier: \n",
            "\n",
            "Training Score for LGBMClassifier:  100.00\n",
            "Testing Score for LGBMClassifier: 92.65\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        83\n",
            "           1       0.86      0.93      0.89        82\n",
            "           2       0.99      0.91      0.95        80\n",
            "\n",
            "    accuracy                           0.93       245\n",
            "   macro avg       0.93      0.93      0.93       245\n",
            "weighted avg       0.93      0.93      0.93       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[78  5  0]\n",
            " [ 5 76  1]\n",
            " [ 0  7 73]]\n",
            "\n",
            " XGBClassifier:  \n",
            "\n",
            "Training Score for XGBClassifier:   100.00\n",
            "Testing Score for XGBClassifier:  90.20\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92        83\n",
            "           1       0.84      0.88      0.86        82\n",
            "           2       0.97      0.90      0.94        80\n",
            "\n",
            "    accuracy                           0.90       245\n",
            "   macro avg       0.91      0.90      0.90       245\n",
            "weighted avg       0.90      0.90      0.90       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[77  6  0]\n",
            " [ 8 72  2]\n",
            " [ 0  8 72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "rus=SMOTETomek()\n",
        "Xrus_train,yrus_train =rus.fit_resample (train_x.iloc[:,1:],train_y)\n",
        "\n",
        "print(Counter(yrus_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbLxUuB0mGRd",
        "outputId": "27c710ed-e37e-47ef-de3c-206a943213f9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 385, 2: 384, 0: 382})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xrus_train, Xrus_valid, yrus_train, yrus_valid = train_test_split(Xrus_train, yrus_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Jxweo8fAmrZn"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,classifier in classifiers:\n",
        "    clf=classifier.fit(Xrus_train,yrus_train)\n",
        "    y_pred=classifier.predict(Xrus_valid)\n",
        "    print(f'\\n {name} \\n')\n",
        "    print(f'Training Score for {name}  {clf.score(Xrus_train,yrus_train) * 100:.2f}' )\n",
        "    print(f'Testing Score for {name} {clf.score(Xrus_valid,yrus_valid) * 100:.2f}' )\n",
        "    print(f'Classification report  \\n {classification_report(yrus_valid,y_pred)}' )\n",
        "    print(f'Confusion matrix  \\n {confusion_matrix(yrus_valid,y_pred)}' )\n",
        "    #print(f'ROC AUC  : {roc_auc_score(valid_y,y_pred)}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcxUU_Smyin",
        "outputId": "78a4762c-e8eb-42bb-a2ef-6293eec8a49b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Naive Bayes : \n",
            "\n",
            "Training Score for Naive Bayes :  45.33\n",
            "Testing Score for Naive Bayes : 46.75\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.43      0.48        69\n",
            "           1       0.45      0.96      0.61        81\n",
            "           2       0.00      0.00      0.00        81\n",
            "\n",
            "    accuracy                           0.47       231\n",
            "   macro avg       0.33      0.47      0.36       231\n",
            "weighted avg       0.32      0.47      0.36       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[30 39  0]\n",
            " [ 3 78  0]\n",
            " [23 58  0]]\n",
            "\n",
            " KNeighbours : \n",
            "\n",
            "Training Score for KNeighbours :  74.24\n",
            "Testing Score for KNeighbours : 66.23\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.88      0.73        69\n",
            "           1       0.96      0.31      0.47        81\n",
            "           2       0.62      0.83      0.71        81\n",
            "\n",
            "    accuracy                           0.66       231\n",
            "   macro avg       0.74      0.67      0.64       231\n",
            "weighted avg       0.74      0.66      0.63       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[61  0  8]\n",
            " [23 25 33]\n",
            " [13  1 67]]\n",
            "\n",
            " SVM : \n",
            "\n",
            "Training Score for SVM :  48.59\n",
            "Testing Score for SVM : 48.92\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.29      0.40        69\n",
            "           1       0.45      0.96      0.61        81\n",
            "           2       0.56      0.19      0.28        81\n",
            "\n",
            "    accuracy                           0.49       231\n",
            "   macro avg       0.56      0.48      0.43       231\n",
            "weighted avg       0.55      0.49      0.43       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[20 38 11]\n",
            " [ 2 78  1]\n",
            " [ 8 58 15]]\n",
            "\n",
            " LogisticRegression : \n",
            "\n",
            "Training Score for LogisticRegression :  54.89\n",
            "Testing Score for LogisticRegression : 53.68\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.46      0.46        69\n",
            "           1       0.64      0.62      0.63        81\n",
            "           2       0.50      0.52      0.51        81\n",
            "\n",
            "    accuracy                           0.54       231\n",
            "   macro avg       0.53      0.53      0.53       231\n",
            "weighted avg       0.54      0.54      0.54       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[32 11 26]\n",
            " [15 50 16]\n",
            " [22 17 42]]\n",
            "\n",
            " DecisionTree : \n",
            "\n",
            "Training Score for DecisionTree :  100.00\n",
            "Testing Score for DecisionTree : 80.52\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84        69\n",
            "           1       0.78      0.69      0.73        81\n",
            "           2       0.83      0.85      0.84        81\n",
            "\n",
            "    accuracy                           0.81       231\n",
            "   macro avg       0.80      0.81      0.80       231\n",
            "weighted avg       0.80      0.81      0.80       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[61  6  2]\n",
            " [13 56 12]\n",
            " [ 2 10 69]]\n",
            "\n",
            " RandomForest : \n",
            "\n",
            "Training Score for RandomForest :  100.00\n",
            "Testing Score for RandomForest : 92.64\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96        69\n",
            "           1       0.87      0.95      0.91        81\n",
            "           2       0.96      0.88      0.92        81\n",
            "\n",
            "    accuracy                           0.93       231\n",
            "   macro avg       0.93      0.93      0.93       231\n",
            "weighted avg       0.93      0.93      0.93       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[66  3  0]\n",
            " [ 1 77  3]\n",
            " [ 1  9 71]]\n",
            "\n",
            " LGBMClassifier: \n",
            "\n",
            "Training Score for LGBMClassifier:  100.00\n",
            "Testing Score for LGBMClassifier: 94.37\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        69\n",
            "           1       0.93      0.93      0.93        81\n",
            "           2       0.95      0.94      0.94        81\n",
            "\n",
            "    accuracy                           0.94       231\n",
            "   macro avg       0.94      0.95      0.94       231\n",
            "weighted avg       0.94      0.94      0.94       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[67  2  0]\n",
            " [ 2 75  4]\n",
            " [ 1  4 76]]\n",
            "\n",
            " XGBClassifier:  \n",
            "\n",
            "Training Score for XGBClassifier:   100.00\n",
            "Testing Score for XGBClassifier:  92.21\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94        69\n",
            "           1       0.89      0.93      0.91        81\n",
            "           2       0.95      0.90      0.92        81\n",
            "\n",
            "    accuracy                           0.92       231\n",
            "   macro avg       0.92      0.92      0.92       231\n",
            "weighted avg       0.92      0.92      0.92       231\n",
            "\n",
            "Confusion matrix  \n",
            " [[65  3  1]\n",
            " [ 3 75  3]\n",
            " [ 2  6 73]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "cc=BorderlineSMOTE()\n",
        "Xcc_train,ycc_train =cc.fit_resample (train_x.iloc[:,1:],train_y)\n",
        "\n",
        "print(Counter(ycc_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXSdyJ6knHux",
        "outputId": "0e9140d5-86cf-40c4-a0ae-94bf93fa1fe8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 407, 2: 407, 0: 407})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xcc_train, Xcc_valid, ycc_train, ycc_valid = train_test_split(Xcc_train, ycc_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5OoQ9oycnb3U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,classifier in classifiers:\n",
        "    clf=classifier.fit(Xcc_train,ycc_train)\n",
        "    y_pred=classifier.predict(Xcc_valid)\n",
        "    print(f'\\n {name} \\n')\n",
        "    print(f'Training Score for {name}  {clf.score(Xcc_train,ycc_train) * 100:.2f}' )\n",
        "    print(f'Testing Score for {name} {clf.score(Xcc_valid,ycc_valid) * 100:.2f}' )\n",
        "    print(f'Classification report  \\n {classification_report(ycc_valid,y_pred)}' )\n",
        "    print(f'Confusion matrix  \\n {confusion_matrix(ycc_valid,y_pred)}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXpgF9s8nmY7",
        "outputId": "74297a38-217c-45fe-c897-92738346b452"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Naive Bayes : \n",
            "\n",
            "Training Score for Naive Bayes :  64.34\n",
            "Testing Score for Naive Bayes : 57.55\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.46      0.59        83\n",
            "           1       0.48      0.73      0.58        82\n",
            "           2       0.58      0.54      0.56        80\n",
            "\n",
            "    accuracy                           0.58       245\n",
            "   macro avg       0.63      0.58      0.58       245\n",
            "weighted avg       0.64      0.58      0.58       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[38 30 15]\n",
            " [ 6 60 16]\n",
            " [ 1 36 43]]\n",
            "\n",
            " KNeighbours : \n",
            "\n",
            "Training Score for KNeighbours :  75.31\n",
            "Testing Score for KNeighbours : 69.39\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.99      0.80        83\n",
            "           1       0.86      0.15      0.25        82\n",
            "           2       0.69      0.95      0.80        80\n",
            "\n",
            "    accuracy                           0.69       245\n",
            "   macro avg       0.74      0.69      0.62       245\n",
            "weighted avg       0.74      0.69      0.62       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[82  1  0]\n",
            " [36 12 34]\n",
            " [ 3  1 76]]\n",
            "\n",
            " SVM : \n",
            "\n",
            "Training Score for SVM :  86.07\n",
            "Testing Score for SVM : 80.00\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85        83\n",
            "           1       0.69      0.78      0.73        82\n",
            "           2       0.86      0.79      0.82        80\n",
            "\n",
            "    accuracy                           0.80       245\n",
            "   macro avg       0.81      0.80      0.80       245\n",
            "weighted avg       0.81      0.80      0.80       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[69 13  1]\n",
            " [ 9 64  9]\n",
            " [ 1 16 63]]\n",
            "\n",
            " LogisticRegression : \n",
            "\n",
            "Training Score for LogisticRegression :  99.69\n",
            "Testing Score for LogisticRegression : 88.98\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92        83\n",
            "           1       0.92      0.73      0.82        82\n",
            "           2       0.87      0.97      0.92        80\n",
            "\n",
            "    accuracy                           0.89       245\n",
            "   macro avg       0.89      0.89      0.89       245\n",
            "weighted avg       0.89      0.89      0.89       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[80  3  0]\n",
            " [10 60 12]\n",
            " [ 0  2 78]]\n",
            "\n",
            " DecisionTree : \n",
            "\n",
            "Training Score for DecisionTree :  100.00\n",
            "Testing Score for DecisionTree : 82.04\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.88        83\n",
            "           1       0.80      0.72      0.76        82\n",
            "           2       0.77      0.88      0.82        80\n",
            "\n",
            "    accuracy                           0.82       245\n",
            "   macro avg       0.82      0.82      0.82       245\n",
            "weighted avg       0.82      0.82      0.82       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[72  7  4]\n",
            " [ 6 59 17]\n",
            " [ 2  8 70]]\n",
            "\n",
            " RandomForest : \n",
            "\n",
            "Training Score for RandomForest :  100.00\n",
            "Testing Score for RandomForest : 90.61\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92        83\n",
            "           1       0.84      0.89      0.86        82\n",
            "           2       0.96      0.91      0.94        80\n",
            "\n",
            "    accuracy                           0.91       245\n",
            "   macro avg       0.91      0.91      0.91       245\n",
            "weighted avg       0.91      0.91      0.91       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[76  7  0]\n",
            " [ 6 73  3]\n",
            " [ 0  7 73]]\n",
            "\n",
            " LGBMClassifier: \n",
            "\n",
            "Training Score for LGBMClassifier:  100.00\n",
            "Testing Score for LGBMClassifier: 89.80\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.91        83\n",
            "           1       0.83      0.88      0.85        82\n",
            "           2       0.99      0.89      0.93        80\n",
            "\n",
            "    accuracy                           0.90       245\n",
            "   macro avg       0.90      0.90      0.90       245\n",
            "weighted avg       0.90      0.90      0.90       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[77  6  0]\n",
            " [ 9 72  1]\n",
            " [ 0  9 71]]\n",
            "\n",
            " XGBClassifier:  \n",
            "\n",
            "Training Score for XGBClassifier:   99.59\n",
            "Testing Score for XGBClassifier:  89.80\n",
            "Classification report  \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92        83\n",
            "           1       0.84      0.85      0.85        82\n",
            "           2       0.96      0.90      0.93        80\n",
            "\n",
            "    accuracy                           0.90       245\n",
            "   macro avg       0.90      0.90      0.90       245\n",
            "weighted avg       0.90      0.90      0.90       245\n",
            "\n",
            "Confusion matrix  \n",
            " [[78  5  0]\n",
            " [ 9 70  3]\n",
            " [ 0  8 72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sMOTETOMEK + votingclassifier"
      ],
      "metadata": {
        "id": "fGRdex-JonSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "rus=SMOTETomek()\n",
        "Xrus_train,yrus_train =rus.fit_resample (train_x.iloc[:,1:],train_y)\n",
        "\n",
        "print(Counter(yrus_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFLMEEmpoqlm",
        "outputId": "76dd5551-0b3d-449f-b408-863b11a4054f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 387, 2: 383, 0: 381})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이지안 최적화"
      ],
      "metadata": {
        "id": "QoDXonoF1yFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization\n",
        "\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVEaYLL1oyVm",
        "outputId": "bce00921-22e2-4439-c30f-5cbb8c9e489a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.8/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (0.4.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "rf_params={\n",
        "    'max_depth':(1,150),\n",
        "    'n_estimators':(10,200),\n",
        "    'max_samples':(0.5,1),\n",
        "    'max_features':(0.5,1)\n",
        "}\n",
        "\n",
        "def rf_bo(max_depth, n_estimators, max_samples, max_features):\n",
        "  params={\n",
        "      'max_depth':int(round(max_depth)),\n",
        "      'n_estimators':int(round(n_estimators)),\n",
        "      'max_samples':max_samples,\n",
        "      'max_features':max_features\n",
        "  }\n",
        "\n",
        "  model=RandomForestClassifier( **params,  n_jobs=-1, random_state=42)\n",
        "  \n",
        "  X_train,X_valid,y_train,y_valid=train_test_split(Xcc_train.iloc[:,1:],ycc_train,test_size=0.8)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  score=f1_score(y_valid, model.predict(X_valid), average = 'micro')\n",
        "  return score"
      ],
      "metadata": {
        "id": "lv8avNZao5ej"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BO_rf = BayesianOptimization(f=rf_bo,pbounds=rf_params,random_state=3,verbose=2)\n",
        "\n",
        "BO_rf.maximize(init_points=7, n_iter=100)\n",
        "\n",
        "rf_max_params=BO_rf.max['params']\n",
        "rf_max_params['max_depth']=int(rf_max_params['max_depth'])\n",
        "rf_max_params['n_estimators']=int(rf_max_params['n_estimators'])\n",
        "rf_max_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D4FgFi1pL9e",
        "outputId": "22b5d83d-463f-42b9-cd36-f94a53f35ec4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | max_depth | max_fe... | max_sa... | n_esti... |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.7183   \u001b[0m | \u001b[0m83.07    \u001b[0m | \u001b[0m0.8541   \u001b[0m | \u001b[0m0.6455   \u001b[0m | \u001b[0m107.1    \u001b[0m |\n",
            "| \u001b[95m2        \u001b[0m | \u001b[95m0.7516   \u001b[0m | \u001b[95m134.0    \u001b[0m | \u001b[95m0.9481   \u001b[0m | \u001b[95m0.5628   \u001b[0m | \u001b[95m49.38    \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0m0.7004   \u001b[0m | \u001b[0m8.669    \u001b[0m | \u001b[0m0.7204   \u001b[0m | \u001b[0m0.5149   \u001b[0m | \u001b[0m96.8     \u001b[0m |\n",
            "| \u001b[95m4        \u001b[0m | \u001b[95m0.7939   \u001b[0m | \u001b[95m97.72    \u001b[0m | \u001b[95m0.6392   \u001b[0m | \u001b[95m0.8381   \u001b[0m | \u001b[95m122.3    \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m0.7093   \u001b[0m | \u001b[0m4.573    \u001b[0m | \u001b[0m0.7794   \u001b[0m | \u001b[0m0.6296   \u001b[0m | \u001b[0m88.87    \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m0.7465   \u001b[0m | \u001b[0m43.25    \u001b[0m | \u001b[0m0.8466   \u001b[0m | \u001b[0m0.7202   \u001b[0m | \u001b[0m39.8     \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m0.749    \u001b[0m | \u001b[0m82.15    \u001b[0m | \u001b[0m0.8902   \u001b[0m | \u001b[0m0.6532   \u001b[0m | \u001b[0m52.17    \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m104.1    \u001b[0m | \u001b[0m0.5484   \u001b[0m | \u001b[0m0.9191   \u001b[0m | \u001b[0m128.7    \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m0.7554   \u001b[0m | \u001b[0m92.62    \u001b[0m | \u001b[0m0.9022   \u001b[0m | \u001b[0m0.9029   \u001b[0m | \u001b[0m125.4    \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m101.9    \u001b[0m | \u001b[0m0.7782   \u001b[0m | \u001b[0m0.8278   \u001b[0m | \u001b[0m118.5    \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m0.7209   \u001b[0m | \u001b[0m94.39    \u001b[0m | \u001b[0m0.7433   \u001b[0m | \u001b[0m0.5497   \u001b[0m | \u001b[0m117.8    \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m0.7439   \u001b[0m | \u001b[0m99.3     \u001b[0m | \u001b[0m0.7925   \u001b[0m | \u001b[0m0.7478   \u001b[0m | \u001b[0m121.7    \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m0.735    \u001b[0m | \u001b[0m102.2    \u001b[0m | \u001b[0m0.5642   \u001b[0m | \u001b[0m0.5633   \u001b[0m | \u001b[0m119.4    \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m0.7734   \u001b[0m | \u001b[0m35.08    \u001b[0m | \u001b[0m0.8769   \u001b[0m | \u001b[0m0.9378   \u001b[0m | \u001b[0m158.3    \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m0.7311   \u001b[0m | \u001b[0m135.0    \u001b[0m | \u001b[0m0.5857   \u001b[0m | \u001b[0m0.9452   \u001b[0m | \u001b[0m38.71    \u001b[0m |\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m71.89    \u001b[0m | \u001b[0m0.9468   \u001b[0m | \u001b[0m0.8526   \u001b[0m | \u001b[0m35.56    \u001b[0m |\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m0.7298   \u001b[0m | \u001b[0m129.9    \u001b[0m | \u001b[0m0.7407   \u001b[0m | \u001b[0m0.6079   \u001b[0m | \u001b[0m170.7    \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m0.7426   \u001b[0m | \u001b[0m128.7    \u001b[0m | \u001b[0m0.6916   \u001b[0m | \u001b[0m0.8898   \u001b[0m | \u001b[0m89.26    \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m0.7401   \u001b[0m | \u001b[0m12.77    \u001b[0m | \u001b[0m0.6435   \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m151.1    \u001b[0m |\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m0.7503   \u001b[0m | \u001b[0m9.123    \u001b[0m | \u001b[0m0.909    \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m68.6     \u001b[0m |\n",
            "| \u001b[95m21       \u001b[0m | \u001b[95m0.8067   \u001b[0m | \u001b[95m49.02    \u001b[0m | \u001b[95m0.8776   \u001b[0m | \u001b[95m0.8817   \u001b[0m | \u001b[95m149.4    \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m0.7734   \u001b[0m | \u001b[0m11.09    \u001b[0m | \u001b[0m0.9071   \u001b[0m | \u001b[0m0.9995   \u001b[0m | \u001b[0m107.2    \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m0.7234   \u001b[0m | \u001b[0m84.91    \u001b[0m | \u001b[0m0.7585   \u001b[0m | \u001b[0m0.6949   \u001b[0m | \u001b[0m15.1     \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m11.38    \u001b[0m | \u001b[0m0.9879   \u001b[0m | \u001b[0m0.5061   \u001b[0m | \u001b[0m191.2    \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m0.7375   \u001b[0m | \u001b[0m89.22    \u001b[0m | \u001b[0m0.9621   \u001b[0m | \u001b[0m0.5817   \u001b[0m | \u001b[0m106.6    \u001b[0m |\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m0.7426   \u001b[0m | \u001b[0m112.9    \u001b[0m | \u001b[0m0.9228   \u001b[0m | \u001b[0m0.8882   \u001b[0m | \u001b[0m118.3    \u001b[0m |\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m0.7093   \u001b[0m | \u001b[0m47.53    \u001b[0m | \u001b[0m0.571    \u001b[0m | \u001b[0m0.8379   \u001b[0m | \u001b[0m163.1    \u001b[0m |\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m0.7401   \u001b[0m | \u001b[0m96.39    \u001b[0m | \u001b[0m0.9209   \u001b[0m | \u001b[0m0.7323   \u001b[0m | \u001b[0m38.06    \u001b[0m |\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m0.7478   \u001b[0m | \u001b[0m30.27    \u001b[0m | \u001b[0m0.9624   \u001b[0m | \u001b[0m0.6224   \u001b[0m | \u001b[0m87.58    \u001b[0m |\n",
            "| \u001b[0m30       \u001b[0m | \u001b[0m0.7823   \u001b[0m | \u001b[0m31.9     \u001b[0m | \u001b[0m0.9125   \u001b[0m | \u001b[0m0.6086   \u001b[0m | \u001b[0m184.8    \u001b[0m |\n",
            "| \u001b[0m31       \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m116.9    \u001b[0m | \u001b[0m0.9163   \u001b[0m | \u001b[0m0.6473   \u001b[0m | \u001b[0m185.8    \u001b[0m |\n",
            "| \u001b[0m32       \u001b[0m | \u001b[0m0.7068   \u001b[0m | \u001b[0m138.6    \u001b[0m | \u001b[0m0.7305   \u001b[0m | \u001b[0m0.5957   \u001b[0m | \u001b[0m58.18    \u001b[0m |\n",
            "| \u001b[0m33       \u001b[0m | \u001b[0m0.7862   \u001b[0m | \u001b[0m45.35    \u001b[0m | \u001b[0m0.7444   \u001b[0m | \u001b[0m0.9499   \u001b[0m | \u001b[0m189.5    \u001b[0m |\n",
            "| \u001b[0m34       \u001b[0m | \u001b[0m0.7222   \u001b[0m | \u001b[0m4.063    \u001b[0m | \u001b[0m0.7278   \u001b[0m | \u001b[0m0.6915   \u001b[0m | \u001b[0m62.71    \u001b[0m |\n",
            "| \u001b[95m35       \u001b[0m | \u001b[95m0.8297   \u001b[0m | \u001b[95m149.2    \u001b[0m | \u001b[95m0.8058   \u001b[0m | \u001b[95m0.9619   \u001b[0m | \u001b[95m52.76    \u001b[0m |\n",
            "| \u001b[0m36       \u001b[0m | \u001b[0m0.7145   \u001b[0m | \u001b[0m116.9    \u001b[0m | \u001b[0m0.687    \u001b[0m | \u001b[0m0.8786   \u001b[0m | \u001b[0m33.14    \u001b[0m |\n",
            "| \u001b[0m37       \u001b[0m | \u001b[0m0.7772   \u001b[0m | \u001b[0m41.1     \u001b[0m | \u001b[0m0.5165   \u001b[0m | \u001b[0m0.5701   \u001b[0m | \u001b[0m157.4    \u001b[0m |\n",
            "| \u001b[0m38       \u001b[0m | \u001b[0m0.7618   \u001b[0m | \u001b[0m98.78    \u001b[0m | \u001b[0m0.6933   \u001b[0m | \u001b[0m0.9735   \u001b[0m | \u001b[0m40.15    \u001b[0m |\n",
            "| \u001b[0m39       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m73.67    \u001b[0m | \u001b[0m0.7778   \u001b[0m | \u001b[0m0.6595   \u001b[0m | \u001b[0m29.2     \u001b[0m |\n",
            "| \u001b[0m40       \u001b[0m | \u001b[0m0.7516   \u001b[0m | \u001b[0m132.0    \u001b[0m | \u001b[0m0.5486   \u001b[0m | \u001b[0m0.9491   \u001b[0m | \u001b[0m103.3    \u001b[0m |\n",
            "| \u001b[0m41       \u001b[0m | \u001b[0m0.8105   \u001b[0m | \u001b[0m93.62    \u001b[0m | \u001b[0m0.7688   \u001b[0m | \u001b[0m0.8536   \u001b[0m | \u001b[0m63.55    \u001b[0m |\n",
            "| \u001b[0m42       \u001b[0m | \u001b[0m0.7516   \u001b[0m | \u001b[0m4.76     \u001b[0m | \u001b[0m0.7983   \u001b[0m | \u001b[0m0.8862   \u001b[0m | \u001b[0m193.4    \u001b[0m |\n",
            "| \u001b[0m43       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m33.19    \u001b[0m | \u001b[0m0.5468   \u001b[0m | \u001b[0m0.7638   \u001b[0m | \u001b[0m56.84    \u001b[0m |\n",
            "| \u001b[0m44       \u001b[0m | \u001b[0m0.8169   \u001b[0m | \u001b[0m70.23    \u001b[0m | \u001b[0m0.5884   \u001b[0m | \u001b[0m0.8146   \u001b[0m | \u001b[0m127.8    \u001b[0m |\n",
            "| \u001b[0m45       \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m38.76    \u001b[0m | \u001b[0m0.9653   \u001b[0m | \u001b[0m0.8139   \u001b[0m | \u001b[0m146.2    \u001b[0m |\n",
            "| \u001b[0m46       \u001b[0m | \u001b[0m0.7721   \u001b[0m | \u001b[0m41.18    \u001b[0m | \u001b[0m0.779    \u001b[0m | \u001b[0m0.6929   \u001b[0m | \u001b[0m157.6    \u001b[0m |\n",
            "| \u001b[0m47       \u001b[0m | \u001b[0m0.7657   \u001b[0m | \u001b[0m149.6    \u001b[0m | \u001b[0m0.8759   \u001b[0m | \u001b[0m0.5168   \u001b[0m | \u001b[0m53.33    \u001b[0m |\n",
            "| \u001b[0m48       \u001b[0m | \u001b[0m0.7926   \u001b[0m | \u001b[0m149.0    \u001b[0m | \u001b[0m0.6053   \u001b[0m | \u001b[0m0.759    \u001b[0m | \u001b[0m52.73    \u001b[0m |\n",
            "| \u001b[0m49       \u001b[0m | \u001b[0m0.8118   \u001b[0m | \u001b[0m149.5    \u001b[0m | \u001b[0m0.5834   \u001b[0m | \u001b[0m0.9907   \u001b[0m | \u001b[0m52.86    \u001b[0m |\n",
            "| \u001b[0m50       \u001b[0m | \u001b[0m0.7759   \u001b[0m | \u001b[0m49.08    \u001b[0m | \u001b[0m0.5294   \u001b[0m | \u001b[0m0.749    \u001b[0m | \u001b[0m149.0    \u001b[0m |\n",
            "| \u001b[0m51       \u001b[0m | \u001b[0m0.6876   \u001b[0m | \u001b[0m149.7    \u001b[0m | \u001b[0m0.8924   \u001b[0m | \u001b[0m0.6142   \u001b[0m | \u001b[0m52.47    \u001b[0m |\n",
            "| \u001b[0m52       \u001b[0m | \u001b[0m0.7324   \u001b[0m | \u001b[0m93.53    \u001b[0m | \u001b[0m0.5105   \u001b[0m | \u001b[0m0.5145   \u001b[0m | \u001b[0m63.22    \u001b[0m |\n",
            "| \u001b[0m53       \u001b[0m | \u001b[0m0.781    \u001b[0m | \u001b[0m70.56    \u001b[0m | \u001b[0m0.5941   \u001b[0m | \u001b[0m0.9577   \u001b[0m | \u001b[0m127.5    \u001b[0m |\n",
            "| \u001b[0m54       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m70.14    \u001b[0m | \u001b[0m0.6469   \u001b[0m | \u001b[0m0.8476   \u001b[0m | \u001b[0m127.2    \u001b[0m |\n",
            "| \u001b[0m55       \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m93.81    \u001b[0m | \u001b[0m0.9267   \u001b[0m | \u001b[0m0.8303   \u001b[0m | \u001b[0m63.5     \u001b[0m |\n",
            "| \u001b[0m56       \u001b[0m | \u001b[0m0.7286   \u001b[0m | \u001b[0m70.71    \u001b[0m | \u001b[0m0.9617   \u001b[0m | \u001b[0m0.6391   \u001b[0m | \u001b[0m128.0    \u001b[0m |\n",
            "| \u001b[0m57       \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m67.66    \u001b[0m | \u001b[0m0.7095   \u001b[0m | \u001b[0m0.8493   \u001b[0m | \u001b[0m151.5    \u001b[0m |\n",
            "| \u001b[0m58       \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m148.8    \u001b[0m | \u001b[0m0.9109   \u001b[0m | \u001b[0m0.7699   \u001b[0m | \u001b[0m52.65    \u001b[0m |\n",
            "| \u001b[0m59       \u001b[0m | \u001b[0m0.7311   \u001b[0m | \u001b[0m108.6    \u001b[0m | \u001b[0m0.8511   \u001b[0m | \u001b[0m0.7917   \u001b[0m | \u001b[0m76.58    \u001b[0m |\n",
            "| \u001b[0m60       \u001b[0m | \u001b[0m0.7222   \u001b[0m | \u001b[0m41.3     \u001b[0m | \u001b[0m0.6571   \u001b[0m | \u001b[0m0.5946   \u001b[0m | \u001b[0m71.68    \u001b[0m |\n",
            "| \u001b[0m61       \u001b[0m | \u001b[0m0.7542   \u001b[0m | \u001b[0m148.9    \u001b[0m | \u001b[0m0.5897   \u001b[0m | \u001b[0m0.8826   \u001b[0m | \u001b[0m53.43    \u001b[0m |\n",
            "| \u001b[0m62       \u001b[0m | \u001b[0m0.7798   \u001b[0m | \u001b[0m70.01    \u001b[0m | \u001b[0m0.5166   \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m127.9    \u001b[0m |\n",
            "| \u001b[0m63       \u001b[0m | \u001b[0m0.7145   \u001b[0m | \u001b[0m118.0    \u001b[0m | \u001b[0m0.591    \u001b[0m | \u001b[0m0.527    \u001b[0m | \u001b[0m20.52    \u001b[0m |\n",
            "| \u001b[0m64       \u001b[0m | \u001b[0m0.7273   \u001b[0m | \u001b[0m93.46    \u001b[0m | \u001b[0m0.5671   \u001b[0m | \u001b[0m0.7905   \u001b[0m | \u001b[0m63.49    \u001b[0m |\n",
            "| \u001b[0m65       \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m34.92    \u001b[0m | \u001b[0m0.7215   \u001b[0m | \u001b[0m0.7914   \u001b[0m | \u001b[0m158.0    \u001b[0m |\n",
            "| \u001b[0m66       \u001b[0m | \u001b[0m0.7708   \u001b[0m | \u001b[0m98.02    \u001b[0m | \u001b[0m0.5821   \u001b[0m | \u001b[0m0.7116   \u001b[0m | \u001b[0m122.3    \u001b[0m |\n",
            "| \u001b[0m67       \u001b[0m | \u001b[0m0.79     \u001b[0m | \u001b[0m128.2    \u001b[0m | \u001b[0m0.5246   \u001b[0m | \u001b[0m0.9688   \u001b[0m | \u001b[0m175.5    \u001b[0m |\n",
            "| \u001b[0m68       \u001b[0m | \u001b[0m0.7093   \u001b[0m | \u001b[0m18.77    \u001b[0m | \u001b[0m0.7204   \u001b[0m | \u001b[0m0.5094   \u001b[0m | \u001b[0m140.6    \u001b[0m |\n",
            "| \u001b[0m69       \u001b[0m | \u001b[0m0.7772   \u001b[0m | \u001b[0m58.77    \u001b[0m | \u001b[0m0.5608   \u001b[0m | \u001b[0m0.8827   \u001b[0m | \u001b[0m43.97    \u001b[0m |\n",
            "| \u001b[0m70       \u001b[0m | \u001b[0m0.799    \u001b[0m | \u001b[0m48.85    \u001b[0m | \u001b[0m0.9545   \u001b[0m | \u001b[0m0.8912   \u001b[0m | \u001b[0m149.3    \u001b[0m |\n",
            "| \u001b[0m71       \u001b[0m | \u001b[0m0.7388   \u001b[0m | \u001b[0m57.66    \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m0.805    \u001b[0m | \u001b[0m68.05    \u001b[0m |\n",
            "| \u001b[0m72       \u001b[0m | \u001b[0m0.758    \u001b[0m | \u001b[0m45.25    \u001b[0m | \u001b[0m0.5982   \u001b[0m | \u001b[0m0.9061   \u001b[0m | \u001b[0m189.7    \u001b[0m |\n",
            "| \u001b[0m73       \u001b[0m | \u001b[0m0.7465   \u001b[0m | \u001b[0m100.3    \u001b[0m | \u001b[0m0.9133   \u001b[0m | \u001b[0m0.5741   \u001b[0m | \u001b[0m30.54    \u001b[0m |\n",
            "| \u001b[0m74       \u001b[0m | \u001b[0m0.7939   \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m0.9249   \u001b[0m | \u001b[0m0.6073   \u001b[0m | \u001b[0m134.1    \u001b[0m |\n",
            "| \u001b[0m75       \u001b[0m | \u001b[0m0.7247   \u001b[0m | \u001b[0m19.17    \u001b[0m | \u001b[0m0.8203   \u001b[0m | \u001b[0m0.673    \u001b[0m | \u001b[0m104.0    \u001b[0m |\n",
            "| \u001b[0m76       \u001b[0m | \u001b[0m0.7132   \u001b[0m | \u001b[0m70.25    \u001b[0m | \u001b[0m0.5177   \u001b[0m | \u001b[0m0.6468   \u001b[0m | \u001b[0m127.7    \u001b[0m |\n",
            "| \u001b[0m77       \u001b[0m | \u001b[0m0.7657   \u001b[0m | \u001b[0m70.18    \u001b[0m | \u001b[0m0.6743   \u001b[0m | \u001b[0m0.7647   \u001b[0m | \u001b[0m127.7    \u001b[0m |\n",
            "| \u001b[0m78       \u001b[0m | \u001b[0m0.7567   \u001b[0m | \u001b[0m149.7    \u001b[0m | \u001b[0m0.6586   \u001b[0m | \u001b[0m0.9531   \u001b[0m | \u001b[0m52.9     \u001b[0m |\n",
            "| \u001b[0m79       \u001b[0m | \u001b[0m0.7426   \u001b[0m | \u001b[0m125.3    \u001b[0m | \u001b[0m0.6396   \u001b[0m | \u001b[0m0.6362   \u001b[0m | \u001b[0m44.75    \u001b[0m |\n",
            "| \u001b[0m80       \u001b[0m | \u001b[0m0.8182   \u001b[0m | \u001b[0m55.94    \u001b[0m | \u001b[0m0.6877   \u001b[0m | \u001b[0m0.6059   \u001b[0m | \u001b[0m144.1    \u001b[0m |\n",
            "| \u001b[0m81       \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m55.57    \u001b[0m | \u001b[0m0.9224   \u001b[0m | \u001b[0m0.6149   \u001b[0m | \u001b[0m191.7    \u001b[0m |\n",
            "| \u001b[0m82       \u001b[0m | \u001b[0m0.7695   \u001b[0m | \u001b[0m45.16    \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.8184   \u001b[0m | \u001b[0m189.7    \u001b[0m |\n",
            "| \u001b[0m83       \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m17.74    \u001b[0m | \u001b[0m0.5351   \u001b[0m | \u001b[0m0.726    \u001b[0m | \u001b[0m63.57    \u001b[0m |\n",
            "| \u001b[0m84       \u001b[0m | \u001b[0m0.7017   \u001b[0m | \u001b[0m98.13    \u001b[0m | \u001b[0m0.8702   \u001b[0m | \u001b[0m0.5692   \u001b[0m | \u001b[0m122.2    \u001b[0m |\n",
            "| \u001b[0m85       \u001b[0m | \u001b[0m0.6876   \u001b[0m | \u001b[0m110.5    \u001b[0m | \u001b[0m0.8736   \u001b[0m | \u001b[0m0.6739   \u001b[0m | \u001b[0m17.7     \u001b[0m |\n",
            "| \u001b[0m86       \u001b[0m | \u001b[0m0.694    \u001b[0m | \u001b[0m11.29    \u001b[0m | \u001b[0m0.7089   \u001b[0m | \u001b[0m0.6899   \u001b[0m | \u001b[0m107.3    \u001b[0m |\n",
            "| \u001b[0m87       \u001b[0m | \u001b[0m0.7849   \u001b[0m | \u001b[0m70.39    \u001b[0m | \u001b[0m0.5251   \u001b[0m | \u001b[0m0.9667   \u001b[0m | \u001b[0m127.3    \u001b[0m |\n",
            "| \u001b[0m88       \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m129.4    \u001b[0m | \u001b[0m0.6997   \u001b[0m | \u001b[0m0.7953   \u001b[0m | \u001b[0m148.8    \u001b[0m |\n",
            "| \u001b[0m89       \u001b[0m | \u001b[0m0.7823   \u001b[0m | \u001b[0m74.54    \u001b[0m | \u001b[0m0.6048   \u001b[0m | \u001b[0m0.6531   \u001b[0m | \u001b[0m124.0    \u001b[0m |\n",
            "| \u001b[0m90       \u001b[0m | \u001b[0m0.7145   \u001b[0m | \u001b[0m16.48    \u001b[0m | \u001b[0m0.5259   \u001b[0m | \u001b[0m0.7468   \u001b[0m | \u001b[0m49.39    \u001b[0m |\n",
            "| \u001b[0m91       \u001b[0m | \u001b[0m0.7388   \u001b[0m | \u001b[0m128.1    \u001b[0m | \u001b[0m0.6792   \u001b[0m | \u001b[0m0.8223   \u001b[0m | \u001b[0m175.4    \u001b[0m |\n",
            "| \u001b[0m92       \u001b[0m | \u001b[0m0.7708   \u001b[0m | \u001b[0m93.64    \u001b[0m | \u001b[0m0.9617   \u001b[0m | \u001b[0m0.7215   \u001b[0m | \u001b[0m63.77    \u001b[0m |\n",
            "| \u001b[0m93       \u001b[0m | \u001b[0m0.6991   \u001b[0m | \u001b[0m83.82    \u001b[0m | \u001b[0m0.5331   \u001b[0m | \u001b[0m0.8271   \u001b[0m | \u001b[0m22.55    \u001b[0m |\n",
            "| \u001b[0m94       \u001b[0m | \u001b[0m0.7337   \u001b[0m | \u001b[0m73.84    \u001b[0m | \u001b[0m0.9316   \u001b[0m | \u001b[0m0.8751   \u001b[0m | \u001b[0m29.32    \u001b[0m |\n",
            "| \u001b[0m95       \u001b[0m | \u001b[0m0.7234   \u001b[0m | \u001b[0m70.23    \u001b[0m | \u001b[0m0.6285   \u001b[0m | \u001b[0m0.943    \u001b[0m | \u001b[0m132.3    \u001b[0m |\n",
            "| \u001b[0m96       \u001b[0m | \u001b[0m0.7913   \u001b[0m | \u001b[0m97.46    \u001b[0m | \u001b[0m0.5501   \u001b[0m | \u001b[0m0.9793   \u001b[0m | \u001b[0m122.6    \u001b[0m |\n",
            "| \u001b[0m97       \u001b[0m | \u001b[0m0.7298   \u001b[0m | \u001b[0m9.898    \u001b[0m | \u001b[0m0.6906   \u001b[0m | \u001b[0m0.9514   \u001b[0m | \u001b[0m199.5    \u001b[0m |\n",
            "| \u001b[0m98       \u001b[0m | \u001b[0m0.79     \u001b[0m | \u001b[0m95.85    \u001b[0m | \u001b[0m0.8421   \u001b[0m | \u001b[0m0.6894   \u001b[0m | \u001b[0m183.3    \u001b[0m |\n",
            "| \u001b[0m99       \u001b[0m | \u001b[0m0.7375   \u001b[0m | \u001b[0m127.6    \u001b[0m | \u001b[0m0.6848   \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m29.99    \u001b[0m |\n",
            "| \u001b[0m100      \u001b[0m | \u001b[0m0.7503   \u001b[0m | \u001b[0m127.5    \u001b[0m | \u001b[0m0.6282   \u001b[0m | \u001b[0m0.8912   \u001b[0m | \u001b[0m146.5    \u001b[0m |\n",
            "| \u001b[0m101      \u001b[0m | \u001b[0m0.735    \u001b[0m | \u001b[0m144.1    \u001b[0m | \u001b[0m0.7379   \u001b[0m | \u001b[0m0.7831   \u001b[0m | \u001b[0m25.56    \u001b[0m |\n",
            "| \u001b[0m102      \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m140.2    \u001b[0m | \u001b[0m0.5418   \u001b[0m | \u001b[0m0.8271   \u001b[0m | \u001b[0m68.21    \u001b[0m |\n",
            "| \u001b[0m103      \u001b[0m | \u001b[0m0.7503   \u001b[0m | \u001b[0m55.91    \u001b[0m | \u001b[0m0.5965   \u001b[0m | \u001b[0m0.6504   \u001b[0m | \u001b[0m143.9    \u001b[0m |\n",
            "| \u001b[0m104      \u001b[0m | \u001b[0m0.7478   \u001b[0m | \u001b[0m42.13    \u001b[0m | \u001b[0m0.9766   \u001b[0m | \u001b[0m0.671    \u001b[0m | \u001b[0m134.2    \u001b[0m |\n",
            "| \u001b[0m105      \u001b[0m | \u001b[0m0.7529   \u001b[0m | \u001b[0m31.75    \u001b[0m | \u001b[0m0.8812   \u001b[0m | \u001b[0m0.8455   \u001b[0m | \u001b[0m184.7    \u001b[0m |\n",
            "| \u001b[0m106      \u001b[0m | \u001b[0m0.749    \u001b[0m | \u001b[0m97.76    \u001b[0m | \u001b[0m0.5573   \u001b[0m | \u001b[0m0.7502   \u001b[0m | \u001b[0m121.9    \u001b[0m |\n",
            "| \u001b[0m107      \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m62.31    \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m0.7812   \u001b[0m | \u001b[0m45.74    \u001b[0m |\n",
            "=========================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 149,\n",
              " 'max_features': 0.8058109389693928,\n",
              " 'max_samples': 0.9619012083054632,\n",
              " 'n_estimators': 52}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params={\n",
        "    'gamma':(0,20),\n",
        "    'max_depth':(1,2000),\n",
        "    'subsample':(0.5,1),\n",
        "    'eta' : (0.001, 0.4)\n",
        "}"
      ],
      "metadata": {
        "id": "38-Vuj-tqaWw"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_bo(eta, gamma,max_depth, subsample ):\n",
        "  params={\n",
        "      'learning_rate' :max(eta, 0),\n",
        "      'gamma':int(round(gamma)),\n",
        "      'max_depth':int(round(max_depth)),\n",
        "      'subsample':int(round(subsample)),\n",
        "  }\n",
        "  model=XGBClassifier(**params, n_jobs=-1, random_state=42)\n",
        "  X_train,X_valid,y_train,y_valid=train_test_split(Xcc_train.iloc[:,1:],ycc_train,test_size=0.2)\n",
        "\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  score=f1_score(y_valid,model.predict(X_valid), average='micro')\n",
        "  return score"
      ],
      "metadata": {
        "id": "klM5EJZCqdYm"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BO_xgb = BayesianOptimization(f=xgb_bo,pbounds=xgb_params,random_state=3,verbose=2)\n",
        "\n",
        "\n",
        "# Bayesian Optimization을 실행해보세요\n",
        "BO_xgb.maximize(init_points=7,n_iter=100)\n",
        "xgb_max_params=BO_xgb.max['params']\n",
        "xgb_max_params['max_depth']=int(xgb_max_params['max_depth'])\n",
        "xgb_max_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCpioPDCqlYX",
        "outputId": "4b65741e-03b3-4ec8-b9d8-796211aa77c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |    eta    |   gamma   | max_depth | subsample |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.852    \u001b[0m | \u001b[0m0.2208   \u001b[0m | \u001b[0m14.16    \u001b[0m | \u001b[0m582.5    \u001b[0m | \u001b[0m0.7554   \u001b[0m |\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m0.7959   \u001b[0m | \u001b[0m0.3573   \u001b[0m | \u001b[0m17.93    \u001b[0m | \u001b[0m252.0    \u001b[0m | \u001b[0m0.6036   \u001b[0m |\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m0.8673   \u001b[0m | \u001b[95m0.02154  \u001b[0m | \u001b[95m8.816    \u001b[0m | \u001b[95m60.72    \u001b[0m | \u001b[95m0.7284   \u001b[0m |\n",
            "| \u001b[95m4        \u001b[0m | \u001b[95m0.8929   \u001b[0m | \u001b[95m0.26     \u001b[0m | \u001b[95m5.57     \u001b[0m | \u001b[95m1.353e+03\u001b[0m | \u001b[95m0.7954   \u001b[0m |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_params={\n",
        "    'n_estimators':(30,100),\n",
        "    'max_depth':(1,2000),\n",
        "    'subsample':(0.5,1)\n",
        "}"
      ],
      "metadata": {
        "id": "aYQ1Ge74q4_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgbm_bo(n_estimators,max_depth, subsample):\n",
        "  params={\n",
        "      'n_estimaotrs':int(round(n_estimators)),\n",
        "      'max_depth':int(round(max_depth)),\n",
        "      'subsample':int(round(subsample)),\n",
        "  }\n",
        "  model=LGBMClassifier(**params, n_jobs=-1, random_state=42)\n",
        "  X_train,X_valid,y_train,y_valid=train_test_split(Xcc_train.iloc[:,1:],ycc_train,test_size=0.2)\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  score=f1_score(y_valid,model.predict(X_valid),average='micro')\n",
        "  return score"
      ],
      "metadata": {
        "id": "9W0vvM9oq8tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BO_lgbm = BayesianOptimization(f=lgbm_bo,pbounds=lgbm_params,random_state=3,verbose=2)\n",
        "\n",
        "\n",
        "# Bayesian Optimization을 실행해보세요\n",
        "BO_lgbm.maximize(init_points=7,n_iter=100)\n",
        "lgbm_max_params=BO_lgbm.max['params']\n",
        "lgbm_max_params['n_estimators']=int(lgbm_max_params['n_estimators'])\n",
        "lgbm_max_params['max_depth']=int(lgbm_max_params['max_depth'])\n",
        "lgbm_max_params"
      ],
      "metadata": {
        "id": "WhWQa2s6rFkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LGBM = LGBMClassifier(**lgbm_max_params)\n",
        "XGB = XGBClassifier(**xgb_max_params)\n",
        "RF = RandomForestClassifier(**rf_max_params)\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "# VotingClassifier 정의\n",
        "VC = VotingClassifier(estimators=[('rf',RF),('xgb',XGB),('lgbm',LGBM)],voting='soft')"
      ],
      "metadata": {
        "id": "KT9YmXh0rI0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VC.fit(Xcc_train,ycc_train)"
      ],
      "metadata": {
        "id": "6OfOFqRgrLHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=VC.predict(test_x.iloc[:,1:])"
      ],
      "metadata": {
        "id": "M6pOEKwfsTbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/스마트공장/sample_submission (3).csv')"
      ],
      "metadata": {
        "id": "iQuSwFgszdPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Y_Class']=pred"
      ],
      "metadata": {
        "id": "qZKRM9IHzjq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Y_Class'].value_counts()"
      ],
      "metadata": {
        "id": "_FpN1GzozeU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv(\"0227_pred3.csv\",index=False)"
      ],
      "metadata": {
        "id": "nmEjfvaSzpfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8blAbNRRM8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}